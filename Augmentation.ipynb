{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46588\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('data/raw/new_clean_data_all.xlsx')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34599\n",
      "3443\n",
      "279\n",
      "209\n",
      "7362\n",
      "557\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "all_labelize_df = []\n",
    "new_column=['無標註','自殺與憂鬱','無助或無望','正向文字','其他負向文字','生理反應或醫療狀況','自殺行為']\n",
    "for label in new_column:\n",
    "    all_labelize_df.append(df[df[label] == 1].loc[:])\n",
    "for i in all_labelize_df:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "35\n",
      "30\n",
      "200\n",
      "50\n",
      "20\n",
      "34399\n",
      "3243\n",
      "244\n",
      "179\n",
      "7162\n",
      "507\n",
      "119\n"
     ]
    }
   ],
   "source": [
    "# TODO: split \"all_labelize_df\" into \"test_labelize_df\" and \"labelize_df\"\n",
    "# random_state = 1\n",
    "test_labelize_df = []\n",
    "labelize_df = []\n",
    "for idx, a_df in enumerate(all_labelize_df):\n",
    "    n0 = 40\n",
    "    if idx == 0:\n",
    "        n0 = 200\n",
    "    elif idx == 1:\n",
    "        n0 = 200\n",
    "    elif idx == 2:\n",
    "        n0 = 35\n",
    "    elif idx == 3:\n",
    "        n0 = 30\n",
    "    elif idx == 4:\n",
    "        n0 = 200\n",
    "    elif idx == 5:\n",
    "        n0 = 50\n",
    "    else:\n",
    "        n0 = 20\n",
    "    test_labelize_df.append(a_df.sample(n=n0, random_state=12345))\n",
    "    labelize_df.append(a_df.drop(test_labelize_df[-1].index))\n",
    "for i in test_labelize_df:\n",
    "    print(len(i))\n",
    "for i in labelize_df:\n",
    "    print(len(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0                                         0\n",
      "No.                                                1\n",
      "TextID                                    0038f0569e\n",
      "Title                                       憂鬱症的我...\n",
      "Sentence      以下文長...如果排版上有問題請見諒:loudly_crying_face:\n",
      "無標註                                                1\n",
      "自殺與憂鬱                                              0\n",
      "無助或無望                                              0\n",
      "正向文字                                               0\n",
      "其他負向文字                                             0\n",
      "生理反應或醫療狀況                                          0\n",
      "自殺行為                                               0\n",
      "Name: 0, dtype: object\n",
      "(34399, 12)\n",
      "(1, 12)\n",
      "(34400, 12)\n"
     ]
    }
   ],
   "source": [
    "print(labelize_df[0].iloc[0])\n",
    "print(labelize_df[0].shape)\n",
    "SMALL_DF = labelize_df[0].iloc[:1]\n",
    "print((SMALL_DF).shape)\n",
    "# print(type(labelize_df[0]))\n",
    "# labelize_df[0].append(SMALL_DF)\n",
    "print(pd.concat([labelize_df[0], (SMALL_DF)], ignore_index=True).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34399, 12)\n",
      "(24399, 12)\n",
      "(2500, 12)\n",
      "(2500, 12)\n",
      "(2500, 12)\n",
      "(2500, 12)\n",
      "augment:  (3000, 12)\n",
      "augment:  (3000, 12)\n",
      "augment:  (2744, 12)\n",
      "augment:  (2679, 12)\n",
      "augment:  (3000, 12)\n",
      "augment:  (3007, 12)\n",
      "augment:  (2619, 12)\n",
      "(3000, 12)\n",
      "(3000, 12)\n",
      "(2744, 12)\n",
      "(2679, 12)\n",
      "(3000, 12)\n",
      "(3007, 12)\n",
      "(2619, 12)\n"
     ]
    }
   ],
   "source": [
    "# split Augmentation Data\n",
    "all_middle_df = labelize_df[0]\n",
    "print(all_middle_df.shape)\n",
    "to_add = 2500\n",
    "Augment_df = []\n",
    "for i in range(4):\n",
    "    Augment_df.append(all_middle_df.sample(n=to_add, random_state=12345))\n",
    "    all_middle_df = all_middle_df.drop(Augment_df[-1].index)\n",
    "print(all_middle_df.shape)\n",
    "labelize_df[0] = all_middle_df\n",
    "\n",
    "for i in range(len(labelize_df)):\n",
    "    labelize_df[i] = labelize_df[i].reset_index(drop=True)\n",
    "# for df in labelize_df:\n",
    "#     print(df)\n",
    "for i in range(len(Augment_df)):\n",
    "    Augment_df[i] = Augment_df[i].reset_index(drop=True)\n",
    "for df in Augment_df:\n",
    "    print(df.shape)\n",
    "to_train = 3000\n",
    "training_df = []\n",
    "\n",
    "augment_id = 0\n",
    "for idx, a_df in enumerate(labelize_df):\n",
    "    augment_label = new_column[idx]\n",
    "    if a_df.shape[0] > to_train:\n",
    "        training_df.append(a_df.sample(n=to_train, random_state=12345))\n",
    "        print(\"augment: \",training_df[-1].shape)\n",
    "    else:\n",
    "        to_augment_df = a_df\n",
    "        boundary = a_df.shape[0]\n",
    "        for i in range(to_add):\n",
    "            # try: \n",
    "                # print(idx, i)\n",
    "                if len( str(Augment_df[augment_id].at[i, 'Sentence'])) < 5:\n",
    "                    augment_sentence = str(a_df.at[i % boundary, 'Sentence']) + str(Augment_df[augment_id].at[i, 'Sentence'])\n",
    "                else:\n",
    "                    augment_sentence = str(a_df.at[i % boundary, 'Sentence']) + str(Augment_df[augment_id].at[i, 'Sentence'])[:5]\n",
    "                to_augment_df = pd.concat([to_augment_df, a_df.iloc[i % boundary:(i % boundary)+1]], ignore_index=True)\n",
    "                to_augment_df.at[boundary+i, 'Sentence'] = augment_sentence\n",
    "            # except:\n",
    "            #     print(i % boundary)\n",
    "        training_df.append(to_augment_df)\n",
    "        print(\"augment: \",to_augment_df.shape)\n",
    "        augment_id += 1\n",
    "for df in training_df:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['No.', 'TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '無助或無望', '正向文字',\n",
      "       '其他負向文字', '生理反應或醫療狀況', '自殺行為'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'No.', 'TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱',\n",
      "       '無助或無望', '正向文字', '其他負向文字', '生理反應或醫療狀況', '自殺行為'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "augmented_df = pd.concat(training_df,axis=0, ignore_index=True).drop(['Unnamed: 0'], axis=1)\n",
    "print(augmented_df.columns)\n",
    "augmented_df.to_excel('data/raw/augmented_by_categories_0525_v2.xlsx')\n",
    "test_df = pd.concat(test_labelize_df,axis=0, ignore_index=True)\n",
    "print(test_df.columns)\n",
    "test_df.to_excel('data/raw/augmented_test_0525_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Unnamed: 0', 'No.', 'TextID', 'Title', 'Sentence', '無標註',\n",
      "       '自殺與憂鬱', '無助或無望', '正向文字', '其他負向文字', '生理反應或醫療狀況', '自殺行為'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# # 4/7\n",
    "# # 數量比較少的['無助或無望','正向文字','生理反應或醫療狀況','自殺行為']先各補1000句看看觀察效果\n",
    "# to_add_class = ['無助或無望','正向文字','生理反應或醫療狀況','自殺行為']\n",
    "# to_add = 500\n",
    "# random_neutral_df = labelize_df[0].sample(n=to_add*4, random_state=1).reset_index()\n",
    "# print(random_neutral_df.columns)\n",
    "# wrong_number = []\n",
    "# for i in range(len(to_add_class)):\n",
    "#     k = 0\n",
    "#     if i == 0:\n",
    "#         k = 2\n",
    "#     elif i == 1:\n",
    "#         k = 3\n",
    "#     elif i == 2:\n",
    "#         k = 5\n",
    "#     else:\n",
    "#         k = 6\n",
    "#     for j in range(to_add):\n",
    "#         random_neutral_df.at[i*to_add+j, 'Sentence'] = str(random_neutral_df.at[i*to_add+j, 'Sentence']) + str(labelize_df[k].sample(n=1, random_state = i*to_add+j).reset_index().at[0,'Sentence'])\n",
    "#         random_neutral_df.at[i*to_add+j, to_add_class[i]] = 1\n",
    "#         random_neutral_df.at[i*to_add+j, '無標註'] = 0\n",
    "#     labelize_df[k] = pd.concat([labelize_df[k], random_neutral_df[i*to_add:(i+1)*to_add]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34399\n",
      "3243\n",
      "744\n",
      "684\n",
      "7162\n",
      "1007\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "# for i in labelize_df:\n",
    "#     print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "800\n",
      "744\n",
      "684\n",
      "800\n",
      "800\n",
      "619\n"
     ]
    }
   ],
   "source": [
    "# partial_augment_df = []\n",
    "# for a_df in labelize_df:\n",
    "#     if len(a_df) > 800:\n",
    "#         partial_augment_df.append(a_df.sample(n=800, random_state=1))\n",
    "#     else:\n",
    "#         partial_augment_df.append(a_df)\n",
    "# for i in partial_augment_df:\n",
    "#     print(len(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'No.', 'TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱',\n",
      "       '無助或無望', '正向文字', '其他負向文字', '生理反應或醫療狀況', '自殺行為'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# augmented_df = pd.concat(partial_augment_df,axis=0, ignore_index=True).drop(['index'], axis=1)\n",
    "# print(augmented_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_excel('data/raw/new_clean_data_augmented_split_v2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat(test_labelize_df,axis=0, ignore_index=True)\n",
    "print(test_df.columns)\n",
    "test_df.to_excel('data/raw/augmented_test_0428_v1.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_augmented_df = pd.read_excel('new_clean_data_augmented.xlsx')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "combine_df = pd.read_excel('new_clean_data_all.xlsx')\n",
    "\n",
    "for i in range(len(combine_df)):\n",
    "    if combine_df['其他負向文字'].iloc[i] == 1:\n",
    "        combine_df.at[i, '自殺與憂鬱'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34599\n",
      "10805\n",
      "279\n",
      "209\n",
      "557\n",
      "139\n"
     ]
    }
   ],
   "source": [
    "all_labelize_df = []\n",
    "new_column=['無標註','自殺與憂鬱','無助或無望','正向文字','其他負向文字','生理反應或醫療狀況','自殺行為']\n",
    "for label in new_column:\n",
    "    if label != '其他負向文字':\n",
    "        all_labelize_df.append(combine_df[combine_df[label] == 1].loc[:])\n",
    "for i in all_labelize_df:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'Unnamed: 0', 'No.', 'TextID', 'Title', 'Sentence', '無標註',\n",
      "       '自殺與憂鬱', '無助或無望', '正向文字', '其他負向文字', '生理反應或醫療狀況', '自殺行為'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# 數量比較少的['無助或無望','正向文字','生理反應或醫療狀況','自殺行為']先各補1000句看看觀察效果\n",
    "to_add_class = ['無助或無望','正向文字','生理反應或醫療狀況','自殺行為']\n",
    "to_add = 2000\n",
    "random_neutral_df = all_labelize_df[0].sample(n=to_add*4, random_state=1).reset_index()\n",
    "print(random_neutral_df.columns)\n",
    "wrong_number = []\n",
    "for i in range(len(to_add_class)):\n",
    "    k = 0\n",
    "    if i == 0:\n",
    "        k = 2\n",
    "    elif i == 1:\n",
    "        k = 3\n",
    "    elif i == 2:\n",
    "        k = 4\n",
    "    else:\n",
    "        k = 5\n",
    "    for j in range(to_add):\n",
    "        random_neutral_df.at[i*to_add+j, 'Sentence'] = str(random_neutral_df.at[i*to_add+j, 'Sentence']) + str(all_labelize_df[k].sample(n=1, random_state = i*to_add+j).reset_index().at[0,'Sentence'])\n",
    "        random_neutral_df.at[i*to_add+j, to_add_class[i]] = 1\n",
    "        random_neutral_df.at[i*to_add+j, '無標註'] = 0\n",
    "    all_labelize_df[k] = pd.concat([all_labelize_df[k], random_neutral_df[i*to_add:(i+1)*to_add]], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "2500\n",
      "2279\n",
      "2209\n",
      "2500\n",
      "2139\n"
     ]
    }
   ],
   "source": [
    "partial_augment_df = []\n",
    "for a_df in all_labelize_df:\n",
    "    if len(a_df) > 2500:\n",
    "        partial_augment_df.append(a_df.sample(n=2500, random_state=1))\n",
    "    else:\n",
    "        partial_augment_df.append(a_df)\n",
    "for i in partial_augment_df:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'No.', 'TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱',\n",
      "       '無助或無望', '正向文字', '生理反應或醫療狀況', '自殺行為'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "augmented_df = pd.concat(partial_augment_df,axis=0, ignore_index=True).drop(['index','其他負向文字'], axis=1)\n",
    "print(augmented_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df.to_excel('new_clean_data_augmented_reduce.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
