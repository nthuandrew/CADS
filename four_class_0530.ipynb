{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46588\n",
      "Index(['Unnamed: 0', 'No.', 'TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱',\n",
      "       '無助或無望', '正向文字', '其他負向文字', '生理反應或醫療狀況', '自殺行為', '其他類型'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "seed = 1\n",
    "df = pd.read_excel('data/raw/new_clean_data_all.xlsx')\n",
    "print(len(df))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2565347/2306923281.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['無標註'][idx] = 1\n"
     ]
    }
   ],
   "source": [
    "other_type = []\n",
    "for idx, row in df.iterrows():\n",
    "    if row['無助或無望'] or row['其他負向文字'] or row['生理反應或醫療狀況']:\n",
    "        other_type.append(1)\n",
    "    else:\n",
    "        other_type.append(0)\n",
    "        if row['正向文字']:\n",
    "            df['無標註'][idx] = 1\n",
    "df['其他類型'] = other_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_excel(\"data/final/sentence/four_class_0530.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34808\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "3443\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "139\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "8198\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/final/sentence/four_class_0530.xlsx')\n",
    "target_columns = ['TextID' , 'Title' ,'Sentence','無標註','自殺與憂鬱','自殺行為','其他類型']\n",
    "df = df[target_columns]\n",
    "all_labelize_df = []\n",
    "new_column=['無標註','自殺與憂鬱','自殺行為','其他類型']\n",
    "for label in new_column:\n",
    "    all_labelize_df.append(df[df[label] == 1].loc[:])\n",
    "for i in all_labelize_df:\n",
    "    print(len(i))\n",
    "    print(i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "Label: 無標註\n",
      "number of train data: 27846\n",
      "number of test data: 6962\n",
      "Label: 自殺與憂鬱\n",
      "number of train data: 2754\n",
      "number of test data: 689\n",
      "Label: 自殺行為\n",
      "number of train data: 111\n",
      "number of test data: 28\n",
      "Label: 其他類型\n",
      "number of train data: 6558\n",
      "number of test data: 1640\n",
      "Fold 1\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "Label: 無標註\n",
      "number of train data: 27846\n",
      "number of test data: 6962\n",
      "Label: 自殺與憂鬱\n",
      "number of train data: 2754\n",
      "number of test data: 689\n",
      "Label: 自殺行為\n",
      "number of train data: 111\n",
      "number of test data: 28\n",
      "Label: 其他類型\n",
      "number of train data: 6558\n",
      "number of test data: 1640\n",
      "Fold 2\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "Label: 無標註\n",
      "number of train data: 27846\n",
      "number of test data: 6962\n",
      "Label: 自殺與憂鬱\n",
      "number of train data: 2754\n",
      "number of test data: 689\n",
      "Label: 自殺行為\n",
      "number of train data: 111\n",
      "number of test data: 28\n",
      "Label: 其他類型\n",
      "number of train data: 6558\n",
      "number of test data: 1640\n",
      "Fold 3\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "Label: 無標註\n",
      "number of train data: 27847\n",
      "number of test data: 6961\n",
      "Label: 自殺與憂鬱\n",
      "number of train data: 2755\n",
      "number of test data: 688\n",
      "Label: 自殺行為\n",
      "number of train data: 111\n",
      "number of test data: 28\n",
      "Label: 其他類型\n",
      "number of train data: 6559\n",
      "number of test data: 1639\n",
      "Fold 4\n",
      "Index(['TextID', 'Title', 'Sentence', '無標註', '自殺與憂鬱', '自殺行為', '其他類型'], dtype='object')\n",
      "Label: 無標註\n",
      "number of train data: 27847\n",
      "number of test data: 6961\n",
      "Label: 自殺與憂鬱\n",
      "number of train data: 2755\n",
      "number of test data: 688\n",
      "Label: 自殺行為\n",
      "number of train data: 112\n",
      "number of test data: 27\n",
      "Label: 其他類型\n",
      "number of train data: 6559\n",
      "number of test data: 1639\n"
     ]
    }
   ],
   "source": [
    "all_train_df = [[] for _ in range(5)]\n",
    "all_test_df = [[] for _ in range(5)]\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "for i in range(len(all_labelize_df)):\n",
    "    for idx, (train_index, test_index) in enumerate(skf.split(all_labelize_df[i], [0]*len(all_labelize_df[i]))):\n",
    "        train_df = all_labelize_df[i].iloc[train_index]\n",
    "        test_df = all_labelize_df[i].iloc[test_index]\n",
    "        all_train_df[idx].append(train_df)\n",
    "        all_test_df[idx].append(test_df)\n",
    "    \n",
    "for i in range(5):\n",
    "    print(\"Fold\", i)\n",
    "    train_df = pd.concat(all_train_df[i], axis=0)\n",
    "    test_df = pd.concat(all_test_df[i], axis=0)\n",
    "    print(train_df.columns)\n",
    "    # show number of each class\n",
    "    for label in new_column:\n",
    "        print(\"Label:\", label)\n",
    "        print(\"number of train data:\", len(train_df[train_df[label] == 1]))\n",
    "        print(\"number of test data:\", len(test_df[test_df[label] == 1]))\n",
    "    # save to excel\n",
    "    # train_df.to_excel(\"data/final/sentence/four_class_0530_train_fold_{}.xlsx\".format(i))\n",
    "    # test_df.to_excel(\"data/final/sentence/four_class_0530_test_fold_{}.xlsx\".format(i))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27846\n",
      "2754\n",
      "111\n",
      "6558\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('data/final/sentence/four_class/seed_1/four_class_0530_train_fold_1.xlsx')\n",
    "target_columns = ['TextID' , 'Title' ,'Sentence','無標註','自殺與憂鬱','自殺行為','其他類型']\n",
    "df = df[target_columns]\n",
    "labelize_df = []\n",
    "new_column=['無標註','自殺與憂鬱','自殺行為','其他類型']\n",
    "for label in new_column:\n",
    "    labelize_df.append(df[df[label] == 1].loc[:])\n",
    "for i in labelize_df:\n",
    "    print(len(i))\n",
    "    # print(i.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17846, 7)\n",
      "(7846, 7)\n",
      "(4000, 7)\n",
      "(6000, 7)\n"
     ]
    }
   ],
   "source": [
    "# split Augmentation Data\n",
    "all_middle_df = labelize_df[0]\n",
    "print(all_middle_df.shape)\n",
    "to_add = [4000, 6000]\n",
    "Augment_df = []\n",
    "for i in range(2):\n",
    "    Augment_df.append(all_middle_df.sample(n=to_add[i], random_state=seed))\n",
    "    all_middle_df = all_middle_df.drop(Augment_df[-1].index)\n",
    "print(all_middle_df.shape)\n",
    "labelize_df[0] = all_middle_df\n",
    "\n",
    "for i in range(len(labelize_df)):\n",
    "    labelize_df[i] = labelize_df[i].reset_index(drop=True)\n",
    "# for df in labelize_df:\n",
    "#     print(df)\n",
    "for i in range(len(Augment_df)):\n",
    "    Augment_df[i] = Augment_df[i].reset_index(drop=True)\n",
    "for df in Augment_df:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29460\n",
      "4431\n",
      "133\n",
      "9844\n"
     ]
    }
   ],
   "source": [
    "### new block at 11/13!!! Goal: take A2 sentence into training data\n",
    "df_A2 = pd.read_excel('data/article/split_output_A2_v2_answer.xlsx')\n",
    "df_A2 = df_A2[target_columns]\n",
    "# DF = pd.concat([df, df_A2], axis=0, ignore_index=True)\n",
    "all_labelize_df_A2 = []\n",
    "for label in new_column:\n",
    "    all_labelize_df_A2.append(df_A2[df_A2[label] == 1].loc[:])\n",
    "for i in all_labelize_df_A2:\n",
    "    print(len(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37306, 7)\n",
      "(7185, 7)\n",
      "(244, 7)\n",
      "(16402, 7)\n"
     ]
    }
   ],
   "source": [
    "# ### new block at 11/13!!! Goal: combine A1 training data and A2 training data\n",
    "for i in range(len(labelize_df)):\n",
    "    labelize_df[i] = pd.concat([labelize_df[i], all_labelize_df_A2[i]], axis=0, ignore_index=True)\n",
    "    print(labelize_df[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(len(labelize_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labelize:  (37306, 7)\n",
      "augment:  (16000, 7)\n",
      "labelize:  (7185, 7)\n",
      "augment:  (11185, 7)\n",
      "labelize:  (244, 7)\n",
      "augment:  (6244, 7)\n",
      "labelize:  (16402, 7)\n",
      "augment:  (16000, 7)\n",
      "(16000, 7)\n",
      "(11185, 7)\n",
      "(6244, 7)\n",
      "(16000, 7)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "to_train = [16000, 0, 0, 16000]\n",
    "target_num = 16000\n",
    "training_df = []\n",
    "\n",
    "augment_id = 0\n",
    "for idx, a_df in enumerate(labelize_df):\n",
    "    print(\"labelize: \",a_df.shape)\n",
    "    # augment_label = new_column[idx]\n",
    "    if a_df.shape[0] > target_num:\n",
    "        training_df.append(a_df.sample(n=to_train[idx], random_state=seed))\n",
    "        print(\"augment: \",training_df[-1].shape)\n",
    "    else:\n",
    "        to_augment_df = a_df\n",
    "        boundary = a_df.shape[0]\n",
    "        for i in range(len(Augment_df[augment_id])):\n",
    "            # try: \n",
    "                # print(idx, i)\n",
    "                if len( str(Augment_df[augment_id].at[i, 'Sentence'])) < 5:\n",
    "                    augment_sentence = str(a_df.at[i % boundary, 'Sentence']) + str(Augment_df[augment_id].at[i, 'Sentence'])\n",
    "                else:\n",
    "                    augment_sentence = str(a_df.at[i % boundary, 'Sentence']) + str(Augment_df[augment_id].at[i, 'Sentence'])[:5]\n",
    "                to_augment_df = pd.concat([to_augment_df, a_df.iloc[i % boundary:(i % boundary)+1]], ignore_index=True)\n",
    "                to_augment_df.at[boundary+i, 'Sentence'] = augment_sentence\n",
    "            # except:\n",
    "            #     print(i % boundary)\n",
    "        training_df.append(to_augment_df)\n",
    "        print(\"augment: \",to_augment_df.shape)\n",
    "        augment_id += 1\n",
    "        to_add = to_train\n",
    "for df in training_df:\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_df = pd.concat(training_df,axis=0, ignore_index=True)\n",
    "augmented_df.to_excel('data/final/sentence/four_class/seed_1/four_class_0530_train_augmented_fold_1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
