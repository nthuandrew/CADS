{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1424, 27)\n",
      "(1424, 9)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_path = 'data/article/網路危機_A1_文章危機程度.xlsx'\n",
    "content_path = 'data/article/A1_article.xlsx'\n",
    "label_df = pd.read_excel(label_path)\n",
    "\n",
    "# read content from the worksheet \"contents\" in the excel file\n",
    "content_df = pd.read_excel(content_path, sheet_name=\"contents\")\n",
    "# convert the content to string\n",
    "label_df['TextID'] = label_df['TextID'].astype(str)\n",
    "content_df['TextID'] = content_df['TextID'].astype(str)\n",
    "print(label_df.shape)\n",
    "print(content_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = label_df['Crisis_Level'].tolist()\n",
    "label_textid = label_df['TextID'].tolist()\n",
    "dic = {}\n",
    "for i in range(len(label_textid)):\n",
    "    dic[label_textid[i]] = labels[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_textid = content_df['TextID'].tolist()\n",
    "content_label = []\n",
    "for textid in content_textid:\n",
    "    if textid not in dic:\n",
    "        print(textid)\n",
    "        print(type(textid))\n",
    "    else:\n",
    "        val = int(dic[textid])\n",
    "        to_save = ''\n",
    "        if val == 0:\n",
    "            to_save = \"d:0\"\n",
    "        elif val == 1:\n",
    "            to_save = \"a:A\"\n",
    "        elif val == 2:\n",
    "            to_save = \"b:B\"\n",
    "        else:\n",
    "            to_save = \"c:C\"\n",
    "        content_label.append(to_save)\n",
    "content_df['Crisis_Level'] = content_label\n",
    "# content_df.to_excel('data/article/A1_article_true_labeled.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1424 1424 1424 1240 1240 1240\n",
      "2664 2664 2664\n"
     ]
    }
   ],
   "source": [
    "A1_article = pd.read_excel('data/article/A1_article_true_labeled.xlsx')\n",
    "A2_article = pd.read_excel('data/article/A2_二次標註_網路危機訊息標註_1100927_僅全文標註(給致寧).xlsx')\n",
    "A1_content = A1_article['Content(remove_tag)'].tolist()\n",
    "A1_label = A1_article['Crisis_Level'].tolist()\n",
    "A1_textid = A1_article['TextID'].tolist()\n",
    "A1_title = A1_article['Title'].tolist()\n",
    "A2_content = A2_article['Content(remove_tag)'].tolist()\n",
    "A2_label = A2_article['Crisis_Level'].tolist()\n",
    "A2_textid = A2_article['TextID'].tolist()  \n",
    "A2_title = A2_article['Title'].tolist()\n",
    "print(len(A1_content), len(A1_textid), len(A1_label), len(A2_content), len(A2_label), len(A2_textid))\n",
    "A1A2_content = A1_content + A2_content\n",
    "A1A2_label = A1_label + A2_label\n",
    "A1A2_textid = A1_textid + A2_textid\n",
    "A1A2_title = A1_title + A2_title    \n",
    "print(len(A1A2_content), len(A1A2_label), len(A1A2_textid))\n",
    "A1A2_df = pd.DataFrame()\n",
    "A1A2_df['Content'] = A1A2_content\n",
    "A1A2_df['Crisis_Level'] = A1A2_label\n",
    "A1A2_df['TextID'] = A1A2_textid\n",
    "A1A2_df['Title'] = A1A2_title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['SerialID', 'TextID', 'Annotator', 'TextTime', 'Comment', 'Author',\n",
      "       'Title', 'Content', 'Content(remove_tag)', 'Crisis_Level'],\n",
      "      dtype='object')\n",
      "Index(['SerialID', 'TextID', 'Crisis_Level', 'Author', 'Title',\n",
      "       'Content(remove_tag)'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(A1_article.columns)\n",
    "print(A2_article.columns)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do one-hot encoding of \"Crisis_Level\"\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(A1A2_df[['Crisis_Level']])\n",
    "# use the encoder to transform the label\n",
    "one_hot = enc.transform(A1A2_df[['Crisis_Level']]).toarray()\n",
    "add_columns = enc.categories_[0].tolist()\n",
    "A1A2_df[add_columns] = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_1 = A1A2_df['a:A'].tolist()\n",
    "# type1_0 is the complement of type1_1\n",
    "type1_0 = []\n",
    "for i in range(len(type1_1)):\n",
    "    if type1_1[i] == 1:\n",
    "        type1_0.append(0)\n",
    "    else:\n",
    "        type1_0.append(1)\n",
    "# type2_1 is A1A2_df['b:B'] OR A1A2_df['a:A']\n",
    "type2_1 = []\n",
    "for i in range(len(type1_1)):\n",
    "    if type1_1[i] == 1 or A1A2_df['b:B'][i] == 1:\n",
    "        type2_1.append(1)\n",
    "    else:\n",
    "        type2_1.append(0)\n",
    "# type2_0 is the complement of type2_1\n",
    "type2_0 = []\n",
    "for i in range(len(type2_1)):\n",
    "    if type2_1[i] == 1:\n",
    "        type2_0.append(0)\n",
    "    else:\n",
    "        type2_0.append(1)\n",
    "# save\n",
    "A1A2_df['type1_1'] = type1_1\n",
    "A1A2_df['type1_0'] = type1_0\n",
    "A1A2_df['type2_1'] = type2_1\n",
    "A1A2_df['type2_0'] = type2_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Content Crisis_Level      TextID  \\\n",
      "0  以下文長...如果排版上有問題請見諒:loudly_crying_face:\\n\\n其實從小...          b:B  0038f0569e   \n",
      "1  先不管之前我的朋友生了什麼病\\n現在她都好了還硬要給這什麼預後的藥\\n她說對成分會過敏也沒有...          d:0  003eb6998d   \n",
      "2             幹你老師 雖小的一天，垃圾雙面心機婊滾去死吧，你就他媽的繼續演，看你能演多久          d:0  006da49ea0   \n",
      "3  原po要軍種抽籤前一天晚上的課老師突然舉行考試來不及回家，因此只能請我媽代抽，結果好死不死直...          c:C  006f9d99fc   \n",
      "4  不就工作嗎？為什麼都找不到，人生活著為什麼要工作，真的好想趕快死，因為我不敢自殺很痛，所以只...          b:B  007fb1eb08   \n",
      "\n",
      "            Title  a:A  b:B  c:C  d:0  type1_1  type1_0  type2_1  type2_0  \n",
      "0        憂鬱症的我...  0.0  1.0  0.0  0.0      0.0        1        1        0  \n",
      "1            妳很過分  0.0  0.0  0.0  1.0      0.0        1        0        1  \n",
      "2         bad day  0.0  0.0  0.0  1.0      0.0        1        0        1  \n",
      "3  抽到海軍陸戰隊到親子關係破裂  0.0  0.0  1.0  0.0      0.0        1        0        1  \n",
      "4   不就工作嗎（不喜請不要點開  0.0  1.0  0.0  0.0      0.0        1        1        0  \n"
     ]
    }
   ],
   "source": [
    "print(A1A2_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dataframe to excel file\n",
    "# A1A2_df.to_excel('data/article/A1A2_article.xlsx', index=False)\n",
    "A1A2_df.to_excel('data/final/article/A1A2_article.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Content', 'Crisis_Level', 'TextID', 'Title', 'a:A', 'b:B', 'c:C',\n",
      "       'd:0', 'type1_1', 'type1_0', 'type2_1', 'type2_0'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(A1A2_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(917, 12)\n",
      "167\n",
      "250\n",
      "250\n",
      "250\n"
     ]
    }
   ],
   "source": [
    "# reduce the number of data by the ratio of 1:1:1:1\n",
    "seed = 1\n",
    "A1A2_df = pd.read_excel('data/final/article/A1A2_article.xlsx')\n",
    "type_A_num = sum(A1A2_df['a:A'])\n",
    "type_num = [type_A_num, 250, 250, 250]\n",
    "all_kind_of_df = []\n",
    "to_save_df = []\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['a:A'] == 1])\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['b:B'] == 1])\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['c:C'] == 1])\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['d:0'] == 1])\n",
    "for i, a_df in enumerate(all_kind_of_df):\n",
    "    # randomly choose type_A_num data from the dataframe\n",
    "    a_df = a_df.sample(n=type_num[i], random_state=seed)\n",
    "    to_save_df.append(a_df)\n",
    "final_df = pd.concat(to_save_df)\n",
    "# shuffle the dataframe\n",
    "final_df = final_df.sample(frac=1, random_state=seed)\n",
    "# show statistics\n",
    "print(final_df.shape)\n",
    "print(final_df['a:A'].sum())\n",
    "print(final_df['b:B'].sum())\n",
    "print(final_df['c:C'].sum())\n",
    "print(final_df['d:0'].sum())\n",
    "final_df.to_excel('data/final/article/A1A2_article_type3.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_A_num:  485\n",
      "type_B_num:  2179\n",
      "(985, 12)\n",
      "485\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "# reduce the number of data by the ratio of 1:1:1:1\n",
    "seed = 1\n",
    "A1A2_df = pd.read_excel('data/final/article/A1A2_article.xlsx')\n",
    "type_A_num = sum(A1A2_df['type2_1'])\n",
    "type_B_num = sum(A1A2_df['type2_0'])\n",
    "print(\"type_A_num: \", type_A_num)\n",
    "print(\"type_B_num: \", type_B_num)\n",
    "type_num = [type_A_num, 500]\n",
    "all_kind_of_df = []\n",
    "to_save_df = []\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['type2_1'] == 1])\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['type2_0'] == 1])\n",
    "for i, a_df in enumerate(all_kind_of_df):\n",
    "    # randomly choose type_A_num data from the dataframe\n",
    "    a_df = a_df.sample(n=type_num[i], random_state=seed)\n",
    "    to_save_df.append(a_df)\n",
    "final_df = pd.concat(to_save_df)\n",
    "# shuffle the dataframe\n",
    "final_df = final_df.sample(frac=1, random_state=seed)\n",
    "# show statistics\n",
    "print(final_df.shape)\n",
    "print(final_df['type2_1'].sum())\n",
    "print(final_df['type2_0'].sum())\n",
    "final_df.to_excel('data/final/article/A1A2_article_type2.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type_1_num:  167\n",
      "type_2_num:  2497\n",
      "(367, 12)\n",
      "167\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# reduce the number of data by the ratio of 1:1:1:1\n",
    "seed = 1\n",
    "A1A2_df = pd.read_excel('data/final/article/A1A2_article.xlsx')\n",
    "type_A_num = sum(A1A2_df['type1_1'])\n",
    "type_B_num = sum(A1A2_df['type1_0'])\n",
    "print(\"type_1_num: \", type_A_num)\n",
    "print(\"type_2_num: \", type_B_num)\n",
    "type_num = [type_A_num, 200]\n",
    "all_kind_of_df = []\n",
    "to_save_df = []\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['type1_1'] == 1])\n",
    "all_kind_of_df.append(A1A2_df[A1A2_df['type1_0'] == 1])\n",
    "for i, a_df in enumerate(all_kind_of_df):\n",
    "    # randomly choose type_A_num data from the dataframe\n",
    "    a_df = a_df.sample(n=type_num[i], random_state=seed)\n",
    "    to_save_df.append(a_df)\n",
    "final_df = pd.concat(to_save_df)\n",
    "# shuffle the dataframe\n",
    "final_df = final_df.sample(frac=1, random_state=seed)\n",
    "# show statistics\n",
    "print(final_df.shape)\n",
    "print(final_df['type1_1'].sum())\n",
    "print(final_df['type1_0'].sum())\n",
    "final_df.to_excel('data/final/article/A1A2_article_type1.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
